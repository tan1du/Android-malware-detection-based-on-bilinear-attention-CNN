import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
import tensorflow_addons as tfa
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, concatenate, Flatten, Dropout,Lambda,\
    BatchNormalization,multiply,GlobalAveragePooling2D,Reshape,Activation,Concatenate,GlobalMaxPooling2D,Add
from keras.layers import LSTM, Embedding
from tensorflow.keras.backend import batch_dot,sign,sqrt,l2_normalize
from tensorflow.keras.regularizers import l2
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.applications import imagenet_utils
from keras.applications.efficientnet import EfficientNetB4
from tensorflow.keras import Input, Model
from keras import backend as K



os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
import numpy as np
from PIL import Image
import os
import os.path as osp
import random as python_random
import random
random_seed = 12345

random.seed(random_seed)
np.random.seed(random_seed)
python_random.seed(random_seed)
tf.random.set_seed(random_seed)
os.environ['PYTHONHASHSEED'] = str(random_seed)
os.environ['TF_DETERMINISTIC_OPS'] = '1'


path_txts = 'path_txts'
dir_name = "dir_save"
file_name = osp.join(dir_name, 'scores.txt')
CHANNELS = 3
EPOCHS = 250
BATCH_SIZE = 64
IMG_SIZE = 128
IMAGE_TYPE = '.color.png'
CLASS_NAMES = ['goodware', 'malware']

if not os.path.exists(dir_name):
    os.makedirs(dir_name)

def get_label(file_path):
    parts = tf.strings.split(file_path, os.path.sep)
    if parts[-2] == 'goodware':
        return [0]
    else:
        return [1]
def process_img(file_path):
    # label = get_label(file_path)
    img = decode_img(file_path)
    return img
def process_label(file_path):
    label = get_label(file_path)
    # img = decode_img(file_path)
    return label

def get_image(path_img):
    # image = np.asarray(Image.open(path_img))
    # postfix = '/'.join(path_img.decode().split('/')[-2:])
    # image = np.asarray(
    #     Image.open(osp.join('/'.join(path_img.decode().split('/')[:-2]), 'color_without_so', postfix).encode()))
    # with open(path_img, "r") as f:
    #     image = f.read()
    # f.close()
    try:
        image = np.asarray(Image.open(path_img))
        # image = image/255
    except:
        postfix = '/'.join(path_img.decode().split('/')[-2:])
        image = np.asarray(
            Image.open(osp.join('/'.join(path_img.decode().split('/')[:-2]), 'color_without_so', postfix).encode()))
    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)
    return image
def get_text(path_txt):
    # text = np.genfromtxt(path_txt,dtype=[int, float,str])

    # try:
    #     with open(path_txt, "r") as f:
    #         text = f.read()
    # except:
    #     postfix = '/'.join(path_txt.decode().split('/')[-2:])
    #     with open(osp.join('/'.join(path_txt.decode().split('/')[:-2]), 'color_without_so', postfix).encode(), "r") as f:
    #         text = f.read()
    # f.close()
    # text = np.asarray(Image.open(path_txt))
    # with open(path_txt, "r",encoding='utf-8') as f:
    #     text = f.read()
    # f.close()
    text = tf.data.TextLineDataset(path_txt)
    tokenizer = Tokenizer(num_words=10000)
    tokenizer.fit_on_texts(text)
    text = tokenizer.texts_to_matrix(text, mode='binary')

    return text


def get_shape(image):
    return image.shape[0]


def decode_img(path_img):
    image = tf.numpy_function(get_image, [path_img], tf.uint8)
    shape = tf.numpy_function(get_shape, [image], tf.int32)
    image = tf.reshape(image, [shape, 128, CHANNELS])
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, [IMG_SIZE , IMG_SIZE])
    return tf.reshape(image, [IMG_SIZE , IMG_SIZE, CHANNELS])

def decode_text(path_txt):
    text = tf.numpy_function(get_text, [path_txt], tf.int32)
    # text = get_text(path_txt)
    # tokenizer = Tokenizer(num_words=10000)
    # tokenizer.fit_on_texts(text)
    # one_hot_results = tokenizer.texts_to_matrix(text, mode='binary')
    return text
def preprocess_image(image):
  image = tf.image.decode_jpeg(image, channels=3)
  image = tf.image.resize(image, [128, 128])
  image /= 255.0  # normalize to [0,1] range

  return image
def load_and_preprocess_image(path):
  image = tf.io.read_file(path)
  return preprocess_image(image)

def process_path(file_path):
    label = get_label(file_path)
    img = decode_img(file_path)
    return img, label
def process_t(file_path):
    label = get_label(file_path)
    text = decode_text(file_path)
    return text, label

def get_imgs(split: str):
    img = []
    for n in CLASS_NAMES:
        img = img + [os.path.join(path_images, split, n, file) for file in
                  os.listdir(os.path.join(path_images, split, n))]
    return img
# def get_imgs2(split: str):
#     img = []
#     for n in CLASS_NAMES:
#         img = img + [os.path.join(path_images2, split, n, file) for file in
#                   os.listdir(os.path.join(path_images2, split, n))]
#     return img
def get_texts(split: str):
    txt = []
    for n in CLASS_NAMES:
        txt = txt + [os.path.join(path_txts, split, n, file) for file in
                  os.listdir(os.path.join(path_txts, split, n))]
    return txt
def dot_product(x):

    return batch_dot(x[0], x[1], axes=[1,1]) / x[0].get_shape().as_list()[1]

"""
Calculate signed square root

@param
x -> a tensor

"""

def signed_sqrt(x):

    return sign(x) * sqrt(abs(x) + 1e-9)

"""
Calculate L2-norm

@param
x -> a tensor

"""

def L2_norm(x, axis=-1):

    return l2_normalize(x, axis=axis)

def base_model():
    input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))

    x1 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        input)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    x1 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')((x1))
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    x1 = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')((x1))
    x1 = Flatten()(x1)
    x1 = Dense(16, activation='relu')(x1)
    # x1 = Dropout(0.25)(x1)
    output = Dense(1, activation='sigmoid', name='output')(x1)
    base_model = Model(inputs=input, outputs=output)

    return base_model
def base_model2():
    in_lay = Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))

    x1 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        in_lay)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    x1 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x1)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    base_model = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')(x1)
    # base_model = Flatten()(base_model)
    # base_model = Model(inputs=in_lay,outputs=output_)
    # base_model = base_model0()
    pt_depth = 128
    cnn_features_a = base_model
    cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cnn_features_a)
    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cnn_features_a)

    concat = Concatenate(axis=3)([avg_pool, max_pool])
    cbam_feature = Conv2D(1, (5, 5), strides=1, padding='same', activation='sigmoid')(concat)
    # cbam_feature = Conv2D(1, (7, 7), strides=1, padding='same', activation='sigmoid')(cbam_feature)
    x1 = multiply([cbam_feature, cnn_bn_features_a])
    x1 = Flatten()(x1)
    x1 = Dense(10, activation='relu')(x1)
    # x1 = Dropout(0.25)(x1)
    output = Dense(1, activation='sigmoid', name='output')(x1)
    base_model2 = Model(inputs=in_lay, outputs=output)

    return base_model2

def B_CNN():
    K.clear_session()
    tensor_input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))

    model1 = Conv2D(64, (5, 5), activation='relu')(tensor_input)
    model1 = MaxPooling2D((4, 4))(model1)
    model1 = Conv2D(128, (3, 3), activation='relu')(model1)
    model1 = MaxPooling2D((4, 4))(model1)
    model1 = Conv2D(128, (5, 5), activation='relu')((model1))
    model1 = Model(inputs=tensor_input, outputs=model1)

    model2 = Conv2D(64, (5, 5), activation='relu')(tensor_input)
    model2 = MaxPooling2D((4, 4))(model2)
    model2 = Conv2D(128, (3, 3), activation='relu')(model2)
    model2 = MaxPooling2D((4, 4))(model2)
    model2 = Conv2D(128, (5, 5), activation='relu')((model2))
    model2 = Model(inputs=tensor_input, outputs=model2)

    x = model1.output
    z = model2.output_shape
    y = model2.output

    #   rehape to (batch_size, total_pixels, filter_size)
    x = Reshape([z[1] * z[2], z[-1]])(x)

    y = Reshape([z[1] * z[2], z[-1]])(y)

    #   outer products of x, y
    x = Lambda(dot_product)([x, y])

    #   rehape to (batch_size, filter_size_vgg_last_layer*filter_vgg_last_layer)
    x = Reshape([z[-1] * z[-1]])(x)

    #   signed_sqrt
    x = Lambda(signed_sqrt)(x)

    #   L2_norm
    x = Lambda(L2_norm)(x)

    initializer = tf.keras.initializers.GlorotNormal(seed=1)

    # x = GlobalAveragePooling2D()(x)

    x = Dense(units=1, kernel_regularizer=l2(0.0),
                           kernel_initializer=initializer)(x)
    # x = Dense(1, name='output')(x)

    tensor_prediction = Activation("sigmoid")((x))

    model_bilinear = Model(inputs=[tensor_input],
                                        outputs=[tensor_prediction])
    return model_bilinear
def blinear_efficient_atten_two():
    """构建多输入模型"""
    # K.clear_session()
    # x = Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    # x = Lambda(imagenet_utils.preprocess_input)(x)
    #
    # base_model = EfficientNetB4(input_tensor=x, weights="imagenet", include_top=False, pooling="avg",classifier_activation="sigmoid")
    # x = base_model.output
    # x = Dense(1024, activation="relu", name="fc1")(x)
    # x = Dropout(0.5)(x)
    # output_ = Dense(1, activation="sigmoid", name="output")(x)
    #
    # eB_model = Model(inputs=base_model.input, outputs=output_, name="eB4")
    # eB_model.summary()

    in_lay = Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))

    x1 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        in_lay)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    x1 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x1)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    base_model = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')(x1)
    # base_model = Flatten()(base_model)
    # base_model = Model(inputs=in_lay,outputs=output_)
    # base_model = base_model0()
    pt_depth = 128
    cnn_features_a = base_model
    cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))((cnn_features_a))
    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))((cnn_features_a))

    concat = Concatenate(axis=3)([avg_pool, max_pool])
    cbam_feature = Conv2D(1, (5, 5), strides=1, padding='same', activation='sigmoid')(concat)
    # cbam_feature = Conv2D(1, (7, 7), strides=1, padding='same', activation='sigmoid')(cbam_feature)
    model1 = multiply([cbam_feature, cnn_bn_features_a])
    model1 = Model(inputs=in_lay, outputs=model1)

    x2 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        in_lay)
    x2 = MaxPooling2D(pool_size=(4, 4))(x2)
    x2 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x2)
    x2 = MaxPooling2D(pool_size=(4, 4))(x2)
    base_model = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')((x2))
    cnn_features_a = base_model
    cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))((cnn_features_a))
    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))((cnn_features_a))

    concat = Concatenate(axis=3)([avg_pool, max_pool])
    cbam_feature = Conv2D(1, (5, 5), strides=1, padding='same', activation='sigmoid')(concat)
    # cbam_feature = Conv2D(1, (7, 7), strides=1, padding='same', activation='sigmoid')(cbam_feature)
    model2 = multiply([cbam_feature, cnn_bn_features_a])
    # base_model = Flatten()(base_model)
    model2 = Model(inputs=in_lay,outputs=model2)
    # base_model = base_model0()
    # pt_depth = 128
    # cnn_features_a = base_model
    # cnn_bn_features_a = BatchNormalization()(cnn_features_a)
    x = model1.output
    z = model2.output_shape
    y = model2.output

    #   rehape to (batch_size, total_pixels, filter_size)
    x = Reshape([z[1] * z[2], z[-1]])(x)

    y = Reshape([z[1] * z[2], z[-1]])(y)

    #   outer products of x, y
    x = Lambda(dot_product)([x, y])

    #   rehape to (batch_size, filter_size_vgg_last_layer*filter_vgg_last_layer)
    x = Reshape([z[-1] * z[-1]])(x)

    #   signed_sqrt
    x = Lambda(signed_sqrt)(x)

    #   L2_norm
    x = Lambda(L2_norm)(x)

    initializer = tf.keras.initializers.GlorotNormal(seed=1)

    # x = GlobalAveragePooling2D()(x)

    x = Dense(units=1, kernel_regularizer=l2(0.0),
              kernel_initializer=initializer)(x)
    # x = Dense(1, name='output')(x)

    tensor_prediction = Activation("sigmoid")((x))

    model_att_bilinear = Model(inputs=[in_lay],
                               outputs=[tensor_prediction])


    return model_att_bilinear
def blinear_efficient_channel():
    """构建多输入模型"""
    # K.clear_session()
    # x = Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    # x = Lambda(imagenet_utils.preprocess_input)(x)
    #
    # base_model = EfficientNetB4(input_tensor=x, weights="imagenet", include_top=False, pooling="avg",classifier_activation="sigmoid")
    # x = base_model.output
    # x = Dense(1024, activation="relu", name="fc1")(x)
    # x = Dropout(0.5)(x)
    # output_ = Dense(1, activation="sigmoid", name="output")(x)
    #
    # eB_model = Model(inputs=base_model.input, outputs=output_, name="eB4")
    # eB_model.summary()

    in_lay = Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))

    x1 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        in_lay)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    x1 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x1)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    base_model = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')(x1)
    # base_model = Flatten()(base_model)
    # base_model = Model(inputs=in_lay,outputs=output_)
    # base_model = base_model0()
    pt_depth = 128
    cnn_features_a = base_model
    cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    channel = cnn_bn_features_a.shape[-1]

    shared_layer_one = Dense(channel // 8,
                             kernel_initializer='he_normal',
                             activation='relu',
                             use_bias=True,
                             bias_initializer='zeros')

    shared_layer_two = Dense(channel,
                             kernel_initializer='he_normal',
                             use_bias=True,
                             bias_initializer='zeros')

    avg_pool = GlobalAveragePooling2D()(cnn_bn_features_a)
    avg_pool = Reshape((1, 1, channel))(avg_pool)
    assert avg_pool.shape[1:] == (1, 1, channel)
    avg_pool = shared_layer_one(avg_pool)
    assert avg_pool.shape[1:] == (1, 1, channel // 8)
    avg_pool = shared_layer_two(avg_pool)
    assert avg_pool.shape[1:] == (1, 1, channel)

    max_pool = GlobalMaxPooling2D()(cnn_bn_features_a)
    max_pool = Reshape((1, 1, channel))(max_pool)
    assert max_pool.shape[1:] == (1, 1, channel)
    max_pool = shared_layer_one(max_pool)
    assert max_pool.shape[1:] == (1, 1, channel // 8)
    max_pool = shared_layer_two(max_pool)
    assert max_pool.shape[1:] == (1, 1, channel)

    cbam_feature = Add()([avg_pool, max_pool])
    cbam_feature = Activation('hard_sigmoid')(cbam_feature)
    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))((cbam_feature))
    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))((cbam_feature))

    concat = Concatenate(axis=3)([avg_pool, max_pool])
    cbam_feature = Conv2D(1, (5, 5), strides=1, padding='same', activation='sigmoid')(concat)
    # cbam_feature = Conv2D(1, (7, 7), strides=1, padding='same', activation='sigmoid')(cbam_feature)
    model1 = multiply([cbam_feature, cnn_bn_features_a])

    # attention mechanism
    # here we do an attention mechanism to turn pixels in the GAP on an off
    # atten_layer = Conv2D(64, kernel_size=(1, 1), padding="same", activation="relu")(Dropout(0.5)(cnn_bn_features_a))
    # atten_layer = Conv2D(32, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(16, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(8, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # # atten_layer = Conv2D(2, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    #
    # atten_layer = Conv2D(1, kernel_size=(1, 1), padding="valid", activation="sigmoid")(atten_layer)  # H,W,1
    # # fan it out to all of the channels
    # up_c2_w = np.ones((1, 1, 1, pt_depth))  # 1,1,C
    # up_c2 = Conv2D(pt_depth, kernel_size=(1, 1), padding="same", activation="linear", use_bias=False, weights=[up_c2_w])
    # up_c2.trainable = True
    # atten_layer = up_c2(atten_layer)  # H,W,C
    # model1 = multiply([atten_layer, cnn_bn_features_a])  # H,W,C
    # model1 = Lambda(signed_sqrt)(model1)
    # model1 = GlobalAveragePooling2D()(cnn_atten_out_a)
    model1 = Model(inputs=in_lay, outputs=model1)

    x2 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        in_lay)
    x2 = MaxPooling2D(pool_size=(4, 4))(x2)
    x2 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x2)
    x2 = MaxPooling2D(pool_size=(4, 4))(x2)
    base_model = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')((x2))

    cnn_features_a = base_model
    cnn_bn_features_a = BatchNormalization()(cnn_features_a)
    # channel = cnn_bn_features_a.shape[-1]
    #
    # shared_layer_one = Dense(channel // 8,
    #                          kernel_initializer='he_normal',
    #                          activation='relu',
    #                          use_bias=True,
    #                          bias_initializer='zeros')
    #
    # shared_layer_two = Dense(channel,
    #                          kernel_initializer='he_normal',
    #                          use_bias=True,
    #                          bias_initializer='zeros')
    #
    # avg_pool = GlobalAveragePooling2D()(cnn_bn_features_a)
    # avg_pool = Reshape((1, 1, channel))(avg_pool)
    # assert avg_pool.shape[1:] == (1, 1, channel)
    # avg_pool = shared_layer_one(avg_pool)
    # assert avg_pool.shape[1:] == (1, 1, channel // 8)
    # avg_pool = shared_layer_two(avg_pool)
    # assert avg_pool.shape[1:] == (1, 1, channel)
    #
    # max_pool = GlobalMaxPooling2D()(cnn_bn_features_a)
    # max_pool = Reshape((1, 1, channel))(max_pool)
    # assert max_pool.shape[1:] == (1, 1, channel)
    # max_pool = shared_layer_one(max_pool)
    # assert max_pool.shape[1:] == (1, 1, channel // 8)
    # max_pool = shared_layer_two(max_pool)
    # assert max_pool.shape[1:] == (1, 1, channel)
    #
    # cbam_feature = Add()([avg_pool, max_pool])
    # cbam_feature = Activation('hard_sigmoid')(cbam_feature)
    # # cbam_feature = Conv2D(1, (7, 7), strides=1, padding='same', activation='sigmoid')(cbam_feature)
    # model2 = multiply([cbam_feature, cnn_bn_features_a])

    # avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))((cnn_features_a))
    # max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))((cnn_features_a))
    #
    # concat = Concatenate(axis=3)([avg_pool, max_pool])
    # cbam_feature = Conv2D(1, (5, 5), strides=1, padding='same', activation='sigmoid')(concat)
    # # cbam_feature = Conv2D(1, (7, 7), strides=1, padding='same', activation='sigmoid')(cbam_feature)
    # model2 = multiply([cbam_feature, cnn_bn_features_a])
    # base_model = Flatten()(base_model)
    model2 = Model(inputs=in_lay,outputs=cnn_bn_features_a)
    # base_model = base_model0()
    # pt_depth = 128
    # cnn_features_a = base_model
    # cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    # attention mechanism
    # here we do an attention mechanism to turn pixels in the GAP on an off
    # atten_layer = Conv2D(64, kernel_size=(1, 1), padding="same", activation="relu")(Dropout(0.5)(cnn_bn_features_a))
    # atten_layer = Conv2D(32, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(16, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(8, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(1, kernel_size=(1, 1), padding="valid", activation="sigmoid")(atten_layer)  # H,W,1
    # # fan it out to all of the channels
    # up_c2_w = np.ones((1, 1, 1, pt_depth))  # 1,1,C
    # up_c2 = Conv2D(pt_depth, kernel_size=(1, 1), padding="same", activation="linear", use_bias=False, weights=[up_c2_w])
    # up_c2.trainable = True
    # atten_layer = up_c2(atten_layer)  # H,W,C
    # model2 = multiply([atten_layer, cnn_bn_features_a])  # H,W,C
    # # model2 = Lambda(signed_sqrt)(model2)
    # # model2 = GlobalAveragePooling2D()(cnn_atten_out_a)
    # model2 = Model(inputs=in_lay, outputs=model2)

    x = model1.output
    z = model2.output_shape
    y = model2.output

    #   rehape to (batch_size, total_pixels, filter_size)
    x = Reshape([z[1] * z[2], z[-1]])(x)

    y = Reshape([z[1] * z[2], z[-1]])(y)

    #   outer products of x, y
    x = Lambda(dot_product)([x, y])

    #   rehape to (batch_size, filter_size_vgg_last_layer*filter_vgg_last_layer)
    x = Reshape([z[-1] * z[-1]])(x)

    #   signed_sqrt
    x = Lambda(signed_sqrt)(x)

    #   L2_norm
    x = Lambda(L2_norm)(x)

    initializer = tf.keras.initializers.GlorotNormal(seed=1)

    # x = GlobalAveragePooling2D()(x)

    x = Dense(units=1, kernel_regularizer=l2(0.0),
              kernel_initializer=initializer)(x)
    # x = Dense(1, name='output')(x)

    tensor_prediction = Activation("sigmoid")((x))

    model_att_bilinear = Model(inputs=[in_lay],
                               outputs=[tensor_prediction])



    # x1 = Flatten()(x1)
    #
    #
    #
    # x1 = Dense(64, activation='relu')(x1)
    # base_model = Dense(1, activation='sigmoid', name='output')(x1)

    #
     # eB_model.summary()

    return model_att_bilinear


def blinear_efficient_atten():
    """构建多输入模型"""
    # K.clear_session()
    # x = Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    # x = Lambda(imagenet_utils.preprocess_input)(x)
    #
    # base_model = EfficientNetB4(input_tensor=x, weights="imagenet", include_top=False, pooling="avg",classifier_activation="sigmoid")
    # x = base_model.output
    # x = Dense(1024, activation="relu", name="fc1")(x)
    # x = Dropout(0.5)(x)
    # output_ = Dense(1, activation="sigmoid", name="output")(x)
    #
    # eB_model = Model(inputs=base_model.input, outputs=output_, name="eB4")
    # eB_model.summary()

    in_lay = Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))

    x1 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        in_lay)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    x1 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x1)
    x1 = MaxPooling2D(pool_size=(4, 4))(x1)
    base_model = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')(x1)
    # base_model = Flatten()(base_model)
    # base_model = Model(inputs=in_lay,outputs=output_)
    # base_model = base_model0()
    pt_depth = 128
    cnn_features_a = base_model
    cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cnn_features_a)
    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cnn_features_a)

    concat = Concatenate(axis=3)([avg_pool, max_pool])
    cbam_feature = Conv2D(1, (5, 5), strides=1, padding='same', activation='sigmoid')(concat)
    # cbam_feature = Conv2D(1, (7, 7), strides=1, padding='same', activation='sigmoid')(cbam_feature)
    model1 = multiply([cbam_feature, cnn_bn_features_a])

    # attention mechanism
    # here we do an attention mechanism to turn pixels in the GAP on an off
    # atten_layer = Conv2D(64, kernel_size=(1, 1), padding="same", activation="relu")(Dropout(0.5)(cnn_bn_features_a))
    # atten_layer = Conv2D(32, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(16, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(8, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    #
    # atten_layer = Conv2D(1, kernel_size=(1, 1), padding="valid", activation="sigmoid")(atten_layer)  # H,W,1
    # # fan it out to all of the channels
    # up_c2_w = np.ones((1, 1, 1, pt_depth))  # 1,1,C
    # up_c2 = Conv2D(pt_depth, kernel_size=(1, 1), padding="same", activation="linear", use_bias=False, weights=[up_c2_w])
    # up_c2.trainable = True
    # atten_layer = up_c2(Dropout(0.5)(atten_layer)) # H,W,C
    # model1 = multiply([atten_layer, cnn_bn_features_a])  # H,W,C
    # model1 = Lambda(signed_sqrt)(model1)
    # model1 = GlobalAveragePooling2D()(cnn_atten_out_a)
    model1 = Model(inputs=in_lay, outputs=model1)

    x2 = Conv2D(64, kernel_size=5, activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS))(
        in_lay)
    x2 = MaxPooling2D(pool_size=(4, 4))(x2)
    x2 = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x2)
    x2 = MaxPooling2D(pool_size=(4, 4))(x2)
    base_model = Conv2D(filters=128, kernel_size=5, activation='relu', padding='same')((x2))
    # base_model = Flatten()(base_model)
    model2 = Model(inputs=in_lay, outputs=base_model)
    # base_model = base_model0()
    # pt_depth = 128
    # cnn_features_a = base_model
    # cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    # attention mechanism
    # here we do an attention mechanism to turn pixels in the GAP on an off
    # atten_layer = Conv2D(64, kernel_size=(1, 1), padding="same", activation="relu")(Dropout(0.5)(cnn_bn_features_a))
    # atten_layer = Conv2D(32, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(16, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(8, kernel_size=(1, 1), padding="same", activation="relu")(atten_layer)
    # atten_layer = Conv2D(1, kernel_size=(1, 1), padding="valid", activation="sigmoid")(atten_layer)  # H,W,1
    # # fan it out to all of the channels
    # up_c2_w = np.ones((1, 1, 1, pt_depth))  # 1,1,C
    # up_c2 = Conv2D(pt_depth, kernel_size=(1, 1), padding="same", activation="linear", use_bias=False, weights=[up_c2_w])
    # up_c2.trainable = True
    # atten_layer = up_c2(atten_layer)  # H,W,C
    # model2 = multiply([atten_layer, cnn_bn_features_a])  # H,W,C
    # model2 = Lambda(signed_sqrt)(model2)
    # # model2 = GlobalAveragePooling2D()(cnn_atten_out_a)
    # model2 = Model(inputs=in_lay, outputs=model2)

    x = model1.output
    z = model2.output_shape
    y = model2.output

    #   rehape to (batch_size, total_pixels, filter_size)
    x = Reshape([z[1] * z[2], z[-1]])(x)

    y = Reshape([z[1] * z[2], z[-1]])(y)

    #   outer products of x, y
    x = Lambda(dot_product)([x, y])

    #   rehape to (batch_size, filter_size_vgg_last_layer*filter_vgg_last_layer)
    x = Reshape([z[-1] * z[-1]])(x)

    #   signed_sqrt
    x = Lambda(signed_sqrt)(x)

    #   L2_norm
    x = Lambda(L2_norm)(x)

    initializer = tf.keras.initializers.GlorotNormal(seed=1)

    # x = GlobalAveragePooling2D()(x)

    x = Dense(units=1, kernel_regularizer=l2(0.0),
              kernel_initializer=initializer)(x)
    # x = Dense(1, name='output')(x)

    tensor_prediction = Activation("sigmoid")((x))

    model_att_bilinear = Model(inputs=[in_lay],
                               outputs=[tensor_prediction])

    # cnn_atten_out_b = cnn_atten_out_a
    #
    # cnn_out_dot = multiply([cnn_atten_out_a, cnn_atten_out_b])
    # gap_features = GlobalAveragePooling2D()(cnn_out_dot)
    # # gap_dr = Dropout(0.25)(gap_features)
    # out_layer = Dense(1, activation="sigmoid")(gap_features)

    # b_eff_atten_model = Model(inputs=[in_lay], outputs=[out_layer], name="blinear_efficient_atten")



    # x1 = Flatten()(x1)
    #
    #
    #
    # x1 = Dense(64, activation='relu')(x1)
    # base_model = Dense(1, activation='sigmoid', name='output')(x1)

    #
    # eB_model = Model(input1_, outputs=[output_])
    # eB_model.summary()

    return model_att_bilinear
if __name__ == '__main__':
    recall_list, precision_list, accuracy_list, f1_list = [], [], [], []
    file_results = open(file_name, "w")
    file_results.write("Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score\n")

    for a in range(1, 6):
        file_results.write("Run: %d \n" % a)
        print("Run: %d" % a)
        path_images = 'path_image4/image' + str(a)
        # path_images2 = 'path_image/image' + str(a+5)
        # print(path_images)
        # print(path_images2)
        PATH_FILES = osp.join(path_images, "data_splits")
        # PATH_FILES2 = osp.join(path_images2, "data_splits")

        train_imgs = get_imgs('train')
        valid_imgs = get_imgs('val')
        test_imgs = get_imgs('test')
        # print(test_imgs)
        # print(train_imgs)

        train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)
        train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        # train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())
        length_train = train_dataset.reduce(0, lambda x, _: x + 1).numpy()
        batch_train = length_train // BATCH_SIZE
        train_dataset = train_dataset.cache()
        train_dataset = train_dataset.shuffle(buffer_size=length_train, seed=random_seed,
                                              reshuffle_each_iteration=False)
        train_dataset = train_dataset.batch(batch_train)
        train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)

        valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)
        valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        # valid_dataset = valid_dataset.apply(tf.data.experimental.ignore_errors())
        length_valid = valid_dataset.reduce(0, lambda x, _: x + 1).numpy()
        batch_valid = length_valid // BATCH_SIZE
        valid_dataset = valid_dataset.cache()
        valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed=random_seed,
                                              reshuffle_each_iteration=False)
        valid_dataset = valid_dataset.batch(batch_valid)
        valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)

        test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)
        test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        # test_dataset = test_dataset.apply(tf.data.experimental.ignore_errors())
        length_test = test_dataset.reduce(0, lambda x, _: x + 1).numpy()
        batch_test = length_test // BATCH_SIZE
        test_dataset = test_dataset.cache()
        test_dataset = test_dataset.shuffle(buffer_size=length_test, seed=random_seed, reshuffle_each_iteration=False)
        test_dataset = test_dataset.batch(batch_test)
        test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)

        # labels_train = []
        # images_train = []
        #
        # for path_img in train_imgs:
        #     images_train.append(get_image(path_img))
        #     labels_train.append(get_label(path_img))
        #
        # labels_test = []
        # images_test = []
        #
        # for path_img in test_imgs:
        #     images_test.append(get_image(path_img))
        #     labels_test.append(get_label(path_img))
        #
        # images_train = np.array(images_train)
        # images_test = np.array(images_test)
        # # print(images_train.shape)
        # training_label_seq = np.array(labels_train)
        # testing_label_seq = np.array(labels_test)
        file_results = open(file_name, "w")
        file_results.write("Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score\n")

        model = blinear_efficient_atten_two()
        # model.summary()
        # 保存模型图
        # plot_model(model, 'Multi_input_model.png')
        model.compile(optimizer='adam',
                      loss=tf.keras.losses.BinaryCrossentropy(),
                      metrics=['accuracy',
                               tf.keras.metrics.Precision(),
                               tf.keras.metrics.Recall(),
                               tfa.metrics.F1Score(num_classes=2, average="micro", threshold=0.5)])
        es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=55, restore_best_weights=True)
        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp' + '1'),
                                                         save_weights_only=True,
                                                         monitor='val_accuracy',
                                                         mode='max',
                                                         save_best_only=True)
        path_save_model = os.path.join(dir_name, 'model' + '1')

        model.fit(train_dataset, shuffle=True, validation_data=valid_dataset, epochs=EPOCHS,
                  callbacks=[es_callback, cp_callback], verbose=2)
        model.save(path_save_model)

        print("Evaluate the model")

        evaluation_scores = model.evaluate(test_dataset, verbose=2)
        file_results.write("%s  \n" % evaluation_scores[1:])
        file_results.write("#" * 50 + "\n")
        accuracy_list.append(evaluation_scores[1])
        precision_list.append(evaluation_scores[2])
        recall_list.append(evaluation_scores[3])
        f1_list.append(evaluation_scores[4])

        tmp_dir = os.path.join(os.path.dirname(file_name), 'tmp')
        if not os.path.exists(tmp_dir):
            os.makedirs(tmp_dir)
        tmp_file_name = os.path.join(tmp_dir, "round_{}_res.txt".format(1))
        with open(tmp_file_name, 'w') as tmp_f:
            tmp_f.write("Accuracy, Precision, Recall, F1-score\n")
            tmp_f.write("{}, {}, {}, {}".format(evaluation_scores[1], evaluation_scores[2], evaluation_scores[3],
                                                evaluation_scores[4]))

    file_results.write("Average scores: %f %f %f %f" % (np.mean(accuracy_list),
                                                        np.mean(precision_list),
                                                        np.mean(recall_list),
                                                        np.mean(f1_list)))
    file_results.close()
